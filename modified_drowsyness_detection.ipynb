{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be74cb02-a605-457b-b3d0-3cf9766d2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "import win32com.client\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Text-to-speech setup.\n",
    "# This runs in a separate thread so video never freezes.\n",
    "# -------------------------------------------------\n",
    "speaker = win32com.client.Dispatch(\"SAPI.SpVoice\")\n",
    "\n",
    "# Why thread: Speech runs in background, Camera loop stays real-time, this function prevents freezing\n",
    "def speak_async(text):\n",
    "    threading.Thread(\n",
    "        target=lambda: speaker.Speak(text),\n",
    "        daemon=True #daemon=True: Thread dies automatically when program exits.\n",
    "    ).start()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Basic geometry helpers.\n",
    "# We only need distance between two points.\n",
    "# -------------------------------------------------\n",
    "def dist(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Eye Aspect Ratio.\n",
    "# Lower value means eyes are more closed.\n",
    "# Vertical distances (A, B)\n",
    "# Horizontal distance (C)\n",
    "# Landmarks come from scientific facial geometry papers.\n",
    "# -------------------------------------------------\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist(eye[1], eye[5])\n",
    "    B = dist(eye[2], eye[4])\n",
    "    C = dist(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Mouth Aspect Ratio.\n",
    "# Ratio: Works for near and far faces\n",
    "# Higher value means mouth is more open.\n",
    "# -------------------------------------------------\n",
    "def mouth_aspect_ratio(landmarks):\n",
    "    # Correct MediaPipe lip landmarks\n",
    "    top = landmarks[13]\n",
    "    bottom = landmarks[14]\n",
    "    left = landmarks[78]\n",
    "    right = landmarks[308]\n",
    "\n",
    "    vertical = dist(top, bottom)\n",
    "    horizontal = dist(left, right)\n",
    "\n",
    "    return vertical / horizontal\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Draws a semi-transparent panel on the screen.\n",
    "# Used for metrics and system info boxes.\n",
    "# -------------------------------------------------\n",
    "def draw_panel(frame, x1, y1, x2, y2, color=(50,60,70), alpha=0.6):\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (x1,y1), (x2,y2), color, -1)\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1-alpha, 0, frame)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Mediapipe face mesh initialization.\n",
    "# max_num_faces=1; Saves CPU. This is a driver system, not a crowd.\n",
    "# refine_landmarks=True; Enables: Iris landmarks, Better eye accuracy\n",
    "# -------------------------------------------------\n",
    "mp_face = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True\n",
    ")\n",
    "# Landmark indices for eyes\n",
    "LEFT_EYE  = [33,160,158,133,153,144]\n",
    "RIGHT_EYE = [362,385,387,263,373,380]\n",
    "\n",
    "# Thresholds decided empirically\n",
    "EYE_THRESH = 0.23\n",
    "MOUTH_THRESH = 0.40\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ALERT_COOLDOWN   = 5 \n",
    "# After an alert is spoken, wait 5 seconds before allowing the next alert.\n",
    "# Without cooldown: Voice repeats every frame, 30–60 alerts per second, System becomes unusable\n",
    "# 5 seconds? 2 seconds → too frequent, 10 seconds → too late, 5 seconds → balanced\n",
    "# -------------------------------------------------\n",
    "ALERT_COOLDOWN = 5\n",
    "DROWSY_TIME_LIMIT = 1.5 # seconds\n",
    "YAWN_TIME_LIMIT = 1.5 # seconds\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Runtime state variables.\n",
    "# These change continuously while the program runs.\n",
    "# -------------------------------------------------\n",
    "eye_closed_start = None # Stores time when eyes first closed.\n",
    "mouth_open_start = None\n",
    "\n",
    "mouth_open = False # flag prevents multiple yawn counts for one yawn.\n",
    "yawn_count = 0\n",
    "yawn_state = \"Not Yawning\"\n",
    "drowsy_level = 0 # Converted into percentage bar.\n",
    "\n",
    "last_drowsy_alert = 0\n",
    "last_yawn_alert = 0\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Start webcam.\n",
    "# -------------------------------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "prev_time = time.time()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Main loop.\n",
    "# -------------------------------------------------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Mirror view for natural interaction\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    \n",
    "    # FPS calculation with safety against division by zero\n",
    "    now = time.time()\n",
    "    fps = int(1 / max(now - prev_time, 1e-6)) # 1e-6: means 0.000001 seconds. It prevents division by zero.\n",
    "    prev_time = now\n",
    "    \n",
    "    # Convert frame to RGB for Mediapipe\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    ear = 0.0\n",
    "    mar = 0.0\n",
    "    face_count = 0\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        face_count = 1\n",
    "        face = results.multi_face_landmarks[0]\n",
    "        \n",
    "        #MediaPipe gives normalized values (0–1). OpenCV needs pixel coordinates.\n",
    "        # Convert normalized landmarks to pixel coordinates\n",
    "        landmarks = [(int(l.x * w), int(l.y * h)) for l in face.landmark]\n",
    "\n",
    "        left_eye = [landmarks[i] for i in LEFT_EYE]\n",
    "        right_eye = [landmarks[i] for i in RIGHT_EYE]\n",
    "\n",
    "        ear = (eye_aspect_ratio(left_eye) + eye_aspect_ratio(right_eye)) / 2\n",
    "        mar = mouth_aspect_ratio(landmarks)\n",
    "\n",
    "        # print(f\"EAR: {ear:.3f} | MAR: {mar:.3f}\")\n",
    "\n",
    "\n",
    "        # ---------------------------\n",
    "        # Drowsiness detection\n",
    "        # ---------------------------\n",
    "        if ear < EYE_THRESH:\n",
    "            if eye_closed_start is None:\n",
    "                eye_closed_start = now\n",
    "            drowsy_level = min(100, int((now - eye_closed_start) * 60))\n",
    "        else:\n",
    "            eye_closed_start = None\n",
    "            drowsy_level = max(0, drowsy_level - 5)\n",
    "\n",
    "        # ---------------------------\n",
    "        # Yawn detection \n",
    "        # ---------------------------\n",
    "        if mar > MOUTH_THRESH and ear < 0.30:\n",
    "            if not mouth_open:\n",
    "                mouth_open = True\n",
    "                mouth_open_start = now\n",
    "                yawn_state = \"Yawning\"\n",
    "        else:\n",
    "            if mouth_open:\n",
    "                if now - mouth_open_start >= YAWN_TIME_LIMIT:\n",
    "                    yawn_count += 1\n",
    "                mouth_open = False\n",
    "                yawn_state = \"Not Yawning\"\n",
    "\n",
    "        # Face bounding box\n",
    "        xs = [p[0] for p in landmarks]\n",
    "        ys = [p[1] for p in landmarks]\n",
    "        cv2.rectangle(frame, (min(xs), min(ys)), (max(xs), max(ys)), (0,255,0), 2)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Alert handling with cooldown protection.\n",
    "    # -------------------------------------------------\n",
    "    if eye_closed_start and (now - eye_closed_start) >= DROWSY_TIME_LIMIT:\n",
    "        if now - last_drowsy_alert > ALERT_COOLDOWN:\n",
    "            speak_async(\"Drowsiness detected. Stay alert.\")\n",
    "            last_drowsy_alert = now\n",
    "\n",
    "    if yawn_count >= 4:\n",
    "        if now - last_yawn_alert > ALERT_COOLDOWN:\n",
    "            speak_async(\"Frequent yawning detected.\")\n",
    "            last_yawn_alert = now\n",
    "            yawn_count = 0\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # User interface drawing.\n",
    "    # -------------------------------------------------\n",
    "    draw_panel(frame, 10, 10, 350, 190)\n",
    "    cv2.putText(frame, \"METRICS\", (20,35),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(frame, f\"EAR: {ear:.2f}\", (20,70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "    cv2.putText(frame, f\"Yawn State: {yawn_state}\", (20,105),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "    cv2.putText(frame, f\"Yawn Count: {yawn_count}\", (20,140),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "\n",
    "    draw_panel(frame, 360, 10, 760, 190)\n",
    "    cv2.putText(frame, \"SYSTEM INFO\", (390,35),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(frame, f\"Faces: {face_count}\", (390,70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "    cv2.putText(frame, f\"Drowsiness: {drowsy_level}%\", (390,105),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "\n",
    "    cv2.rectangle(frame, (390,135),\n",
    "                  (390 + int(drowsy_level * 3), 155),\n",
    "                  (0,0,255) if drowsy_level >= 70 else (0,255,0), -1)\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {fps}\", (w-100,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Driver Monitoring System\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2654c7-9750-448d-8e5e-3d8b2d4277e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (mp_env)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
